{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want interactive widgets in the notebook when plotting. Use the following magic command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import temmeta and check out the contents of your file\n",
    "you can use temmeta to print the contents as well as do some interactive visualisations of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from temmeta import data_io as dio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"data/sample_data.emd\"\n",
    "f = dio.EMDFile(input_path)\n",
    "f.print_simple_structure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.get_dataset(\"Image\", \"07a19a7f6e4248178f4cf2ab41c0bb07\").plot_interactive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. We use the following tools to export the contents of the emd file and set up the config file for non-rigid registration\n",
    "You will get messages where each dataset was exported to and which parameter file was created. You may get warnings that some image files can not be exported because they do not represent actual images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jnrr import io_tools\n",
    "from jnrr import processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(\"Processing\")\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = io_tools.extract_emd(input_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The paths to the various files are returned by the `extract_emd` function as a dictionary. You will see that for each image dataset a different config file is created. So you can easily choose on which dataset you wish to run the calculation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We don't need the emd file anymore, so it is best practice to close it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can modify the config files with `read_config_file`, edit the dictionary values, and then save the result back out with `write_dict_to_config_file`. Let's say we want to limit the number of images that we want to use for the calculation to save time and resources. We will also edit the regularization parameter `lambda`. The different parameters will hopefully be better documented in the future**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_config = paths[\"config_file_paths\"][2]\n",
    "conf = io_tools.read_config_file(selected_config)\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf[\"numTemplates\"]=\"20\"\n",
    "conf[\"lambda\"]=\"20\"\n",
    "io_tools.write_dict_to_config_file(selected_config, conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Run the non-rigid-registration\n",
    "**Now we perform the calculation on a selected config file. This will calculate the several deformation fields in the images. For convenience, when it is done, the function returns the path to the folder where the results are stored.**\n",
    "\n",
    "**!!! Note that this will only work on Linux systems !!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!matchSeries {selected_config}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculations_folder = processing.calculate_non_rigid_registration(selected_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Apply the deformations to selected datasets\n",
    "\n",
    "**Now use the helper function to apply the deformations to the images and possibly the spectra. You must provide the path to the calculation folder. If you do not supply a path to an image folder, the one in the config file will be taken. One might wish to calculate deformations on one set of images, and apply them to a different set, hence why you have the option. A path to a spectrum dataset must be provided if you desire to apply them; by default none will be performed. The process of applying deformations to large spectrum maps can be quite slow. Check the help of the function to find out what is returned. The results are also stored as hyperspy datasets in a results folder.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(io_tools)\n",
    "reload(processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculations_folder = \"./data/nonrigid_results_002/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_image_folder = paths[\"image_folder_paths\"][2]\n",
    "selected_spectra_folder = paths[\"spectrum_folder_paths\"][0]\n",
    "results = processing.apply_deformations(calculations_folder, selected_image_folder, selected_spectra_folder)\n",
    "averageUndeformed, averageDeformed, spectrumUndeformed, spectrumDeformed = results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize and work with the resulting datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averageUndeformed.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averageDeformed.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrumUndeformed.plot_interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrumDeformed.plot_interactive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check out the TEMMETA examples for further analysis techniques, or convert to a hyperspy object and continue your analysis with hyperspy.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
